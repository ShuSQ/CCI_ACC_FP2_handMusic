const modelParams = { // å°å…¥handtracké»˜èªçš„åƒæ•¸æ¨¡å‹
  flipHorizontal: true, // flip e.g for video
  imageScaleFactor: 0.7, // reduce input image size for gains in speed.
  maxNumBoxes: 1, // maximum number of boxes to detect
  iouThreshold: 0.5, // ioU threshold for non-max suppression
  scoreThreshold: 0.9, // confidence threshold for predictions.
};

const genres = {  // ç”Ÿæˆå°è±¡
  middle: {
    filter: "blur",
    source: "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-3.mp3",
  },
  right: {
    filter: "brightness",
    source: "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3",
  },
  left: {
    filter: "contrast",
    source: "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-10.mp3",
  },
};

// ç²å–é é¢å…ƒç´ 
const video = document.getElementsByTagName("video")[0];
const audio = document.getElementsByTagName("audio")[0];
const canvas = document.getElementsByTagName("canvas")[0];
const context = canvas.getContext("2d");
let model;

function loadModel() {
  handTrack.load().then((_model) => { // è¼‰å…¥æ¨¡å‹ä¹‹å¾Œåˆå§‹åŒ–ä»‹é¢
    // Initial interface after model load.
    // Store model in global model variable
    model = _model;
    model.setModelParameters(modelParams);
    
    runDetection();
    document.getElementById("loading").remove();
  });
}

// è¿”å›ä¸€å€‹promise Returns a promise
handTrack.startVideo(video).then(function (status) {
  if (status) { // è¼‰å…¥è¦–é »æˆåŠŸå¾Œï¼ŒåŠ è¼‰æ¨¡å‹
    loadModel()
  } else {  // elseï¼Œæç¤ºé–‹å•Ÿæ”åƒé ­
    console.log("Please enable camera");
  }
});

function applyFilter(filterType) {  // ç§»é™¤åŸæ¿¾é¡ä¸¦æ·»åŠ æ–°cssæ¿¾é¡
  if (canvas.classList.length > 0) canvas.classList.remove(canvas.classList[0]);
  canvas.classList.add(filterType);
}

function drawText(text, x, y) { // ç¹ªè£½æ–‡æœ¬
  const color = "#4d375d";
  const font = "1.2rem Monoton";

  context.font = font;
  context.fillStyle = color;
  context.fillText(text, x, y);
}

function runDetection() { // æª¢æ¸¬å‡½æ•¸ï¼Œä¸¦æŠŠæ‰‹å‹¢æª¢æ¸¬æ¸²æŸ“åˆ°canvasä¸Š
  model.detect(video).then((predictions) => {
    //Render hand predictions to be displayed on the canvas
    model.renderPredictions(predictions, canvas, context, video);

    //Add genres to canvas
    drawText("Left ğŸ¤šğŸ»", 25, 50);
    drawText("Middle âœŠğŸ»", 250, 50);
    drawText("Right âœ‹ğŸ»", 525, 50, "");

    requestAnimationFrame(runDetection);

    if (predictions.length > 0) {
      let x = predictions[0].bbox[0];
      let y = predictions[0].bbox[1];

      // åŒ¹é…ä½ç½®ä¸¦æ’­æ”¾éŸ³æº
      if (y <= 100) {
        if (x <= 150) {
          //Left
          audio.src = genres.left.source;
          applyFilter(genres.left.filter);
        } else if (x >= 250 && x <= 350) {
          //Middle
          audio.src = genres.middle.source;
          applyFilter(genres.middle.filter);
        } else if (x >= 450) {
          //Right
          audio.src = genres.right.source;
          applyFilter(genres.right.filter);
        }
        //Play the sound
        audio.volume = 1;
        audio.play();
      }
    }
  });
}
